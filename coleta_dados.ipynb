{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yPpp-jPV_Iv"
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import pickle\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nyrOOXyo-gn",
        "outputId": "ee0dd85c-87e4-401c-d1db-fe43d2a18aea"
      },
      "source": [
        "\n",
        "auth = tweepy.OAuthHandler(\"YwQk6cNynKMFhh0M1CWuDft0U\", \"ivOFQPwhhwKrUGeH95ULTUBYyWcqgHNZ8QCsjBnDuZjSY5Uw0D\")\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True,\n",
        "                 retry_count = 15,\n",
        "                 retry_delay = 61, timeout = 120)\n",
        "\n",
        "places = api.geo_search(query=\"BRA\", granularity=\"country\")\n",
        "place_id = places[0].id\n",
        "\n",
        "for page in tweepy.Cursor(api.search, q=\"place:%s\" % place_id, result_type = \"mixed\", count = 450).pages(5000):\n",
        "  for status in page:\n",
        "    status_hashtags = [s['text'] for s in status.entities['hashtags']]\n",
        "    screen_name = status.user.screen_name\n",
        "    status_type = status.metadata['result_type']\n",
        "    verified = status.user.verified\n",
        "    followers = status.user.followers_count\n",
        "    if (len(status_hashtags) > 0):\n",
        "      with open('hashtag_data.pkl', 'ab') as file:\n",
        "        pickle.dump({'user': screen_name, 'tweet_type':status_type,\n",
        "                     'verified': verified, 'followers':followers,\n",
        "                     'hashtags': status_hashtags}, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "files.download(\"hashtag_data.pkl\")\n",
        "data = []\n",
        "\n",
        "with (open(\"hashtag_data.pkl\", \"rb\")) as file:\n",
        "    while True:\n",
        "        try:\n",
        "            data.append(pickle.load(file))\n",
        "        except EOFError:\n",
        "            break\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "del data\n",
        "df.to_csv(\"hashtag_data.csv\", sep = \";\")\n",
        "files.download(\"hashtag_data.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rate limit reached. Sleeping for: 648\n",
            "Rate limit reached. Sleeping for: 692\n",
            "Rate limit reached. Sleeping for: 692\n",
            "Rate limit reached. Sleeping for: 693\n",
            "Rate limit reached. Sleeping for: 694\n",
            "Rate limit reached. Sleeping for: 690\n",
            "Rate limit reached. Sleeping for: 689\n",
            "Rate limit reached. Sleeping for: 682\n",
            "Rate limit reached. Sleeping for: 696\n",
            "Rate limit reached. Sleeping for: 688\n",
            "Rate limit reached. Sleeping for: 692\n",
            "Rate limit reached. Sleeping for: 681\n",
            "Rate limit reached. Sleeping for: 691\n",
            "Rate limit reached. Sleeping for: 694\n"
          ]
        }
      ]
    }
  ]
}